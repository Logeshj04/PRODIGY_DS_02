# PRODIGY_DS_02
# Titanic Survival Prediction - Data Science Internship Task 2

## Overview

This repository contains the Task 2 project of my Data Science Internship at Prodigy Infotech. The task involves performing data cleaning and exploratory data analysis (EDA) on the Titanic dataset from Kaggle, followed by implementing various machine learning models to predict survival.

## Table of Contents

- [Introduction](#introduction)
- [Dataset](#dataset)
- [Data Cleaning](#data-cleaning)
- [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)
- [Modeling](#modeling)
- [Evaluation](#evaluation)
- [Conclusion](#conclusion)
- [Installation](#installation)
- [Usage](#usage)
- [Google Colab](#google-colab)
- [Acknowledgments](#acknowledgments)

## Introduction

This project is part of my Data Science Internship at Prodigy Infotech. The main objectives are:
- To clean and preprocess the Titanic dataset.
- To perform exploratory data analysis (EDA) to uncover insights and patterns.
- To build and evaluate machine learning models for predicting survival on the Titanic.

## Dataset

The dataset used in this project is the Titanic dataset from Kaggle. It contains information about the passengers on the Titanic, including their demographics and whether they survived or not.

## Data Cleaning

In the data cleaning step, the following operations were performed:
- Handling missing values.
- Encoding categorical variables.
- Feature scaling.

## Exploratory Data Analysis (EDA)

During EDA, the following analyses were conducted:
- Statistical summaries of the dataset.
- Visualizations to explore relationships between variables.
- Identification of patterns and trends in the data.

## Modeling

The following machine learning models were implemented to predict survival:
- Logistic Regression
- Support Vector Machines
- Naive Bayes
- KNN
- Decision Tree

## Evaluation

The performance of the models was evaluated and compared based on accuracy scores. Here are the results:
- Naive Bayes: 76%
- Logistic Regression: 75%
- Decision Tree: 74%
- Support Vector Machines: 66%
- KNN: 66%

## Conclusion

The Naive Bayes model performed the best with an accuracy of 76%, followed closely by Logistic Regression with 75%.

## Installation

To run this project, you need to have the following libraries installed:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

## Google Colab
This project was implemented using Google Colab. Colab provides a free and convenient environment to write and execute Python code in the cloud, making it easy to collaborate and share your work. To run this notebook in Google Colab, you can follow these steps:

1. Open your Google Drive.
2. Upload the PRODIGY_DS_02.ipynb notebook to your Drive.
3. Open the notebook with Google Colab.
4. Make sure to upload the Titanic dataset to the appropriate directory in your Colab environment.

## Acknowledgments
 - Prodigy Infotech for the internship opportunity.
 - Kaggle for providing the Titanic dataset.
 - The open-source community for the libraries used in this project.
 - Google Colab for providing a free and powerful platform for running the analyses.
